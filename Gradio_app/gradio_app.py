# -*- coding: utf-8 -*-
"""post partum depression in women RAG

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q2obm41gAwMfDD5wTuh35lVppbLYpFbd

## **Set the API key as environment variable in your environment**

Setting the API key as an environment variable ensures your key stays confidential and makes your code more portable and secure.
"""


import os
os.environ["GEMINI_API_KEY"]= "AIzaSyArj4oYQQ6mk1E7t_UCmM3o1aCSUNTPx04"

print(os.environ["GEMINI_API_KEY"])

"""## **Loading data(Loading PDF file)**

"""


from pypdf import PdfReader
#This code extracts text content from a PDF file and stores it in the variable text.
def load_pdf(file_path):
    reader = PdfReader(file_path)
    text = ""
    for page in reader.pages:
      text += page.extract_text()
    return text
text = load_pdf(file_path= ".\post partum depression (3).pdf")



pdf_text = load_pdf(file_path=".\post partum depression (3).pdf" )

"""# **Splitting the text**

"""
import re

def split_text(text: str):
  split_text = re.split('\n \n', text)
  return [i for i in split_text if i != ""]
#Returns a list containing the cleaned and separated paragraphs.The processed text is stored in a list variable named split_text

text = split_text(pdf_text)

"""# **Embedding the text**

"""

#typing_extensions helps bridge the gap between older Python versions and newer type features, while also offering a glimpse into potential future typing capabilities.

import google.generativeai as genai
from chromadb import Documents, EmbeddingFunction, Embeddings
import os

"""
It checks for a Gemini API key (set as an environment
variable).

If the key is valid, it connects to the API.

It sends the text data and specifies a model for generating the embedding.

Finally, it returns the numerical code representing the meaning of the text.
"""

class GeminiEmbeddingFunction(EmbeddingFunction):
  def __call__(self, input: Documents) -> Embeddings:
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if not gemini_api_key:
      raise ValueError("Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable")
    genai.configure(api_key=gemini_api_key)
    model = "models/embedding-001"
    title = "Custom query"
    return genai.embed_content(model=model,content=input,task_type="retrieval_document",title=title)["embedding"]

"""# **Storing vectors into DB**

### The previous code prepares the text data, the current code creates a database with encoded information (text + embeddings), and future code will utilize the embeddings for retrieval tasks based on user queries. These snippets work together to build a system that understands the meaning of text data and allows efficient retrieval of relevant information.
"""

import chromadb
def create_chroma_db(documents, path, name):
  chroma_client = chromadb.PersistentClient(path=path)
  db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())
  for i, d in enumerate(documents):
    db.add(documents=d, ids=str(i))
  return db, name

"""
**1. Creating a ChromaDB Collection (create_chroma_db):**

1.  Takes text data (list of strings), path, and collection name.

2.   Creates a new database and collection with the given name.

3. Uses GeminiEmbeddingFunction to generate embeddings for added documents.

4. Adds each text piece to the collection with a unique ID.

5. Returns the created database object and collection name.

**2. Loading an Existing ChromaDB Collection (load_chroma_collection):**

1. Takes path and collection name.
2. Retrieves the existing collection with the specified name.
3. Sets the embedding function for consistency (might be used later).
4. Returns the loaded database object.
"""

PATH = "/content/drive/MyDrive/IBM Datahon/final bot"


def load_chroma_collection(path, name):
  chroma_client = chromadb.PersistentClient(path=path)
  db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())
  return db

try:
    db, name = create_chroma_db(documents=text, path=PATH, name="POST_PARTUM_DEPRESSION")
except Exception as e:
    # Handle the case where the collection already exists
    print(f"Collection '{e.args[0]}' already exists. Loading the existing collection.")
    db = load_chroma_collection(path=PATH, name="POST_PARTUM_DEPRESSION")

   
"""# **Retrieval**

"""

def get_relevant_passage(query, db, n_results):
    passage = db.query(query_texts=[query], n_results=n_results)['documents'][0]
    return passage

relevant_text = get_relevant_passage("post partum",db,1)

print(relevant_text)

"""# **Generation**"""

def make_rag_prompt(query, relevant_passage):
    # Escaping and formatting relevant passage for readability
    escaped = relevant_passage.replace("'", "").replace('"', "").replace("\n", " ")

    # Defining the RAG prompt with considerations for non-technical users and a compassionate tone
    prompt = ("""
    You are an AI assistant specializing in postpartum depression support. Your role is to provide clear, comprehensive, and empathetic answers based on the passage provided below.
    Be gentle, considerate, and use friendly language to ensure the person feels heard and understood. When explaining complex concepts, break them down simply, and avoid technical jargon.
    If the passage does not contain useful information for the answer, kindly ignore it and generate a helpful, factual response based on your knowledge.

    QUESTION: '{query}'
    PASSAGE: '{relevant_passage}'

    Answer with empathy, factual accuracy, and helpful guidance:
    """).format(query=query, relevant_passage=escaped)

    return prompt

# def make_rag_prompt(query, relevant_passage):
#     escaped = relevant_passage.replace("'", "").replace('"', "").replace("\n", " ")
#     prompt = ("""You are a helpful and informative bot that answers questions using text from the reference passage included below. \Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \
#           However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \
#             strike a friendly and converstional tone. \
#               If the passage is irrelevant to the answer, you may ignore it.
#                 QUESTION: '{query}'
#                   PASSAGE: '{relevant_passage}'ANSWER:
#                       """).format(query=query, relevant_passage=escaped)
#     return prompt

import google.generativeai as genai
def generate_response(prompt):
    gemini_api_key = os.getenv("GEMINI_API_KEY")
    if not gemini_api_key:
      raise ValueError("Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable")
    genai.configure(api_key=gemini_api_key)
    model = genai.GenerativeModel('gemini-pro')
    answer = model.generate_content(prompt)
    return answer.text

"""# **Bringing it all together**

"""

def generate_answer(db,query):
      #retrieve top 3 relevant text chunks
    relevant_text = get_relevant_passage(query,db,n_results=1)
    prompt = make_rag_prompt(query, relevant_passage="".join(relevant_text)) # joining the relevant chunks to create a single passage
    answer = generate_response(prompt)
    return answer



# Colab-compatible Gradio interface for Postpartum Depression Chatbot with Pre-defined Queries

# !pip install gradio  # Uncomment this line if Gradio is not installed in your Colab environment

import gradio as gr

# Import necessary libraries and functions
# Make sure these are defined or imported in your Colab notebook
# from your_module import get_relevant_passage, make_rag_prompt, generate_response

# Assuming db is defined elsewhere in your Colab notebook


def chatbot_response(message, history):
    response = generate_answer(db, message)
    # Update history with the new message and response
    history.append((message, response))
    return "", history  # Clear the message box and return the updated chatbot history

def handle_button_click(button_text, history):
    response = generate_answer(db, button_text)
    history.append((button_text, response))
    return history, history

# Custom CSS for styling
custom_css = """
body {
    background-color: #1a1a2e;
    color: #ffffff;
}
.gradio-container {
    background-color: #1a1a2e;
}
.chat-message {
    background-color: #16213e;
    border-radius: 10px;
    padding: 10px;
    margin-bottom: 10px;
}
.custom-button {
    background-color: #0f3460;
    border: none;
    color: white;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 16px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 12px;
    transition-duration: 0.4s;
}
.custom-button:hover {
    background-color: #16213e;
}
"""

with gr.Blocks(css=custom_css) as demo:
    gr.Markdown("<h1>üå∏ MaternEASE üå∏</h1>")
    gr.Markdown("<h3>Empowering mothers with support and care for postpartum well-being.</h3>")

    chatbot = gr.Chatbot(elem_id="chatbox", height=400)
    msg = gr.Textbox(placeholder="Ask about symptoms, treatments, or self-care tips...(Use SHIFT+ENTER to POST)", label="Type your message here", lines=3)
    clear = gr.Button("Clear Chat", elem_classes=["clear-btn"])
    submit = gr.Button("Send", elem_classes=["submit-btn"])

    # Pre-defined query buttons with elegant, larger design
    with gr.Row():
        symptoms_btn = gr.Button("Common Symptoms", elem_classes=["custom-button"])
        treatment_btn = gr.Button("üíä Treatment Options", elem_classes=["custom-button"])
        support_btn = gr.Button("ü§ù Support Resources", elem_classes=["custom-button"])
        self_care_btn = gr.Button("üå∏ Self-Care Tips", elem_classes=["custom-button"])

    # Set up message input and button interactions
    msg.submit(fn=chatbot_response, inputs=[msg, chatbot], outputs=[msg, chatbot])
    clear.click(fn=lambda: None, inputs=None, outputs=chatbot, queue=False)
    submit.click(fn=chatbot_response, inputs=[msg, chatbot], outputs=[msg, chatbot])

    # Handle button clicks and update chat history
    symptoms_btn.click(fn=handle_button_click, inputs=[symptoms_btn, chatbot], outputs=[chatbot, chatbot])
    treatment_btn.click(fn=handle_button_click, inputs=[treatment_btn, chatbot], outputs=[chatbot, chatbot])
    support_btn.click(fn=handle_button_click, inputs=[support_btn, chatbot], outputs=[chatbot, chatbot])
    self_care_btn.click(fn=handle_button_click, inputs=[self_care_btn, chatbot], outputs=[chatbot, chatbot])

# Launch with debug mode
demo.launch(debug=True, share=True)

